{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tough-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "import pandas as pd \n",
    "from scipy.io import wavfile\n",
    "\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import regularizers, activations\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.utils import np_utils, to_categorical\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from datetime import datetime \n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "polished-tongue",
   "metadata": {},
   "outputs": [],
   "source": [
    "us8k_df = pd.read_pickle(\"us8k_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "elementary-congress",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model():\n",
    "    model1 = Sequential()\n",
    "    \n",
    "    #layer-1\n",
    "    model1.add(Conv2D(filters=24, kernel_size=5, input_shape=(128, 128, 1),\n",
    "                      kernel_regularizer=regularizers.l2(1e-3)))\n",
    "    model1.add(MaxPooling2D(pool_size=(3,3), strides=3))\n",
    "    model1.add(Activation(activations.relu))\n",
    "    \n",
    "    #layer-2\n",
    "    model1.add(Conv2D(filters=36, kernel_size=4, padding='valid', kernel_regularizer=regularizers.l2(1e-3)))\n",
    "    model1.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "    model1.add(Activation(activations.relu))\n",
    "    \n",
    "    #layer-3\n",
    "    model1.add(Conv2D(filters=48, kernel_size=3, padding='valid'))\n",
    "    model1.add(Activation(activations.relu))\n",
    "    \n",
    "    model1.add(GlobalAveragePooling2D())\n",
    "    \n",
    "    #layer-4 (1st dense layer)\n",
    "    model1.add(Dense(60, activation='relu'))\n",
    "    model1.add(Dropout(0.5))\n",
    "    \n",
    "    #layer-5 (2nd dense layer)\n",
    "    model1.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    \n",
    "    # compile\n",
    "    model1.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "    \n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afraid-louisville",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 124, 124, 24)      624       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 41, 41, 24)        0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 41, 41, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 38, 38, 36)        13860     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 19, 19, 36)        0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 19, 19, 36)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 17, 17, 48)        15600     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 17, 17, 48)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 60)                2940      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                610       \n",
      "=================================================================\n",
      "Total params: 33,634\n",
      "Trainable params: 33,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = init_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "altered-vermont",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(fold_k, data, X_dim=(128, 128, 1)):\n",
    "    X_train = np.stack(data[data.fold != fold_k].melspectrogram.to_numpy())\n",
    "    X_test = np.stack(data[data.fold == fold_k].melspectrogram.to_numpy())\n",
    "\n",
    "    y_train = data[data.fold != fold_k].label.to_numpy()\n",
    "    y_test = data[data.fold == fold_k].label.to_numpy()\n",
    "\n",
    "    XX_train = X_train.reshape(X_train.shape[0], *X_dim)\n",
    "    XX_test = X_test.reshape(X_test.shape[0], *X_dim)\n",
    "    \n",
    "    yy_train = to_categorical(y_train)\n",
    "    yy_test = to_categorical(y_test)\n",
    "    \n",
    "    return XX_train, XX_test, yy_train, yy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "phantom-strap",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_fold(fold_k, data, epochs=100, num_batch_size=32):\n",
    "    # split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(fold_k, data)\n",
    "\n",
    "    # init data augmention\n",
    "    #train_datagen, val_datagen = init_data_aug()\n",
    "    \n",
    "    # fit augmentation\n",
    "    #train_datagen.fit(X_train)\n",
    "    #val_datagen.fit(X_train)\n",
    "\n",
    "    # init model\n",
    "    model = init_model()\n",
    "\n",
    "    # pre-training accuracy\n",
    "    score = model.evaluate(X_test, y_test, batch_size=num_batch_size, verbose=0)\n",
    "    print(\"Pre-training accuracy: %.4f%%\\n\" % (100 * score[1]))\n",
    "    \n",
    "    # train the model\n",
    "    start = datetime.now()\n",
    "    history = model.fit(X_train,y_train, epochs=epochs,validation_data=(X_test,y_test),batch_size=num_batch_size)\n",
    "    end = datetime.now()\n",
    "    print(\"Training completed in time: \", end - start, '\\n')\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "raised-puppy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(tot_history):\n",
    "    \"\"\"Show accuracy and loss graphs for train and test sets.\"\"\"\n",
    "\n",
    "    for i, history in enumerate(tot_history):\n",
    "        print('\\n({})'.format(i+1))\n",
    "\n",
    "        plt.figure(figsize=(15,5))\n",
    "\n",
    "        plt.subplot(121)\n",
    "        plt.plot(history.history['accuracy'])\n",
    "        plt.plot(history.history['val_accuracy'])\n",
    "        plt.grid(linestyle='--')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "        plt.subplot(122)\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.grid(linestyle='--')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['train', 'validation'], loc='upper left')\n",
    "            \n",
    "        plt.show()\n",
    "\n",
    "        print('\\tMax validation accuracy: %.4f %%' % (np.max(history.history['val_accuracy']) * 100))\n",
    "        print('\\tMin validation loss: %.5f' % np.min(history.history['val_loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "legislative-prior",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "\n",
      "(1)\n",
      "\n",
      "Pre-training accuracy: 12.7148%\n",
      "\n",
      "Epoch 1/10\n",
      "246/246 [==============================] - 20s 80ms/step - loss: 2.3856 - accuracy: 0.1284 - val_loss: 2.2273 - val_accuracy: 0.1798\n",
      "Epoch 2/10\n",
      "246/246 [==============================] - 20s 83ms/step - loss: 2.0865 - accuracy: 0.2281 - val_loss: 1.9073 - val_accuracy: 0.3116\n",
      "Epoch 3/10\n",
      "246/246 [==============================] - 20s 81ms/step - loss: 1.8182 - accuracy: 0.3340 - val_loss: 1.6201 - val_accuracy: 0.4502\n",
      "Epoch 4/10\n",
      "246/246 [==============================] - 19s 79ms/step - loss: 1.5907 - accuracy: 0.4251 - val_loss: 1.2363 - val_accuracy: 0.5097\n",
      "Epoch 5/10\n",
      "246/246 [==============================] - 19s 77ms/step - loss: 1.4799 - accuracy: 0.4705 - val_loss: 1.2059 - val_accuracy: 0.6163\n",
      "Epoch 6/10\n",
      "246/246 [==============================] - 19s 78ms/step - loss: 1.4028 - accuracy: 0.4974 - val_loss: 1.1718 - val_accuracy: 0.5407\n",
      "Epoch 7/10\n",
      "246/246 [==============================] - 19s 78ms/step - loss: 1.3253 - accuracy: 0.5317 - val_loss: 1.0674 - val_accuracy: 0.6140\n",
      "Epoch 8/10\n",
      "246/246 [==============================] - 19s 78ms/step - loss: 1.2716 - accuracy: 0.5484 - val_loss: 1.0105 - val_accuracy: 0.6735\n",
      "Epoch 9/10\n",
      "246/246 [==============================] - 19s 78ms/step - loss: 1.2200 - accuracy: 0.5704 - val_loss: 1.0471 - val_accuracy: 0.6266\n",
      "Epoch 10/10\n",
      "246/246 [==============================] - 19s 79ms/step - loss: 1.1580 - accuracy: 0.5940 - val_loss: 1.0137 - val_accuracy: 0.6037\n",
      "Training completed in time:  0:03:15.241489 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "FOLD_K = 1\n",
    "\n",
    "history1 = []\n",
    "\n",
    "print('-'*80)\n",
    "print(\"\\n({})\\n\".format(FOLD_K))\n",
    "    \n",
    "history = process_fold(FOLD_K, us8k_df, epochs=10)\n",
    "history1.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "retained-greenhouse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "\n",
      "(2)\n",
      "\n",
      "Pre-training accuracy: 13.5135%\n",
      "\n",
      "Epoch 1/20\n",
      "246/246 [==============================] - 20s 79ms/step - loss: 2.2161 - accuracy: 0.1810 - val_loss: 2.0861 - val_accuracy: 0.2320\n",
      "Epoch 2/20\n",
      "246/246 [==============================] - 19s 78ms/step - loss: 1.7950 - accuracy: 0.3389 - val_loss: 1.7313 - val_accuracy: 0.4369\n",
      "Epoch 3/20\n",
      "246/246 [==============================] - 20s 83ms/step - loss: 1.5271 - accuracy: 0.4475 - val_loss: 1.5172 - val_accuracy: 0.4155\n",
      "Epoch 4/20\n",
      "246/246 [==============================] - 19s 79ms/step - loss: 1.3574 - accuracy: 0.5261 - val_loss: 1.2841 - val_accuracy: 0.5023\n",
      "Epoch 5/20\n",
      "246/246 [==============================] - 20s 79ms/step - loss: 1.2446 - accuracy: 0.5662 - val_loss: 1.2709 - val_accuracy: 0.5214\n",
      "Epoch 6/20\n",
      "246/246 [==============================] - 20s 82ms/step - loss: 1.1462 - accuracy: 0.6128 - val_loss: 1.3169 - val_accuracy: 0.5709\n",
      "Epoch 7/20\n",
      "246/246 [==============================] - 19s 78ms/step - loss: 1.0926 - accuracy: 0.6354 - val_loss: 1.1629 - val_accuracy: 0.5743\n",
      "Epoch 8/20\n",
      "246/246 [==============================] - 19s 76ms/step - loss: 1.0576 - accuracy: 0.6456 - val_loss: 1.1281 - val_accuracy: 0.6261\n",
      "Epoch 9/20\n",
      "246/246 [==============================] - 20s 81ms/step - loss: 1.0050 - accuracy: 0.6660 - val_loss: 1.1145 - val_accuracy: 0.6261\n",
      "Epoch 10/20\n",
      "246/246 [==============================] - 19s 78ms/step - loss: 0.9764 - accuracy: 0.6831 - val_loss: 1.1019 - val_accuracy: 0.6363\n",
      "Epoch 11/20\n",
      "246/246 [==============================] - 20s 82ms/step - loss: 0.9273 - accuracy: 0.6919 - val_loss: 1.1323 - val_accuracy: 0.5800\n",
      "Epoch 12/20\n",
      "246/246 [==============================] - 20s 80ms/step - loss: 0.9190 - accuracy: 0.6984 - val_loss: 0.9451 - val_accuracy: 0.6655\n",
      "Epoch 13/20\n",
      "246/246 [==============================] - 19s 79ms/step - loss: 0.8832 - accuracy: 0.7132 - val_loss: 0.9100 - val_accuracy: 0.6486\n",
      "Epoch 14/20\n",
      "246/246 [==============================] - 19s 78ms/step - loss: 0.8505 - accuracy: 0.7268 - val_loss: 0.9921 - val_accuracy: 0.6655\n",
      "Epoch 15/20\n",
      "246/246 [==============================] - 19s 79ms/step - loss: 0.8309 - accuracy: 0.7339 - val_loss: 1.0312 - val_accuracy: 0.6565\n",
      "Epoch 16/20\n",
      "246/246 [==============================] - 19s 78ms/step - loss: 0.8207 - accuracy: 0.7337 - val_loss: 0.9515 - val_accuracy: 0.6689\n",
      "Epoch 17/20\n",
      "246/246 [==============================] - 19s 79ms/step - loss: 0.7912 - accuracy: 0.7445 - val_loss: 0.9938 - val_accuracy: 0.6070\n",
      "Epoch 18/20\n",
      "246/246 [==============================] - 19s 79ms/step - loss: 0.7832 - accuracy: 0.7532 - val_loss: 0.9899 - val_accuracy: 0.6430\n",
      "Epoch 19/20\n",
      "246/246 [==============================] - 20s 79ms/step - loss: 0.7515 - accuracy: 0.7594 - val_loss: 0.9627 - val_accuracy: 0.6858\n",
      "Epoch 20/20\n",
      "246/246 [==============================] - 19s 79ms/step - loss: 0.7194 - accuracy: 0.7731 - val_loss: 1.1232 - val_accuracy: 0.6171\n",
      "Training completed in time:  0:06:30.990396 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "FOLD_K = 2\n",
    "\n",
    "print('-'*80)\n",
    "print(\"\\n({})\\n\".format(FOLD_K))\n",
    "    \n",
    "history = process_fold(FOLD_K, us8k_df, epochs=20)\n",
    "history1.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "exotic-institution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "\n",
      "(3)\n",
      "\n",
      "Pre-training accuracy: 12.8649%\n",
      "\n",
      "Epoch 1/20\n",
      "244/244 [==============================] - 20s 81ms/step - loss: 2.3394 - accuracy: 0.1324 - val_loss: 2.2186 - val_accuracy: 0.2076\n",
      "Epoch 2/20\n",
      "244/244 [==============================] - 19s 78ms/step - loss: 2.0395 - accuracy: 0.2381 - val_loss: 1.7368 - val_accuracy: 0.3686\n",
      "Epoch 3/20\n",
      "244/244 [==============================] - 19s 78ms/step - loss: 1.7447 - accuracy: 0.3594 - val_loss: 1.5623 - val_accuracy: 0.4151\n",
      "Epoch 4/20\n",
      "244/244 [==============================] - 19s 79ms/step - loss: 1.5828 - accuracy: 0.4262 - val_loss: 1.3876 - val_accuracy: 0.4659\n",
      "Epoch 5/20\n",
      "244/244 [==============================] - 21s 84ms/step - loss: 1.4550 - accuracy: 0.4762 - val_loss: 1.3540 - val_accuracy: 0.4627\n",
      "Epoch 6/20\n",
      "244/244 [==============================] - 19s 79ms/step - loss: 1.3612 - accuracy: 0.5118 - val_loss: 1.3268 - val_accuracy: 0.5481\n",
      "Epoch 7/20\n",
      "244/244 [==============================] - 19s 77ms/step - loss: 1.3043 - accuracy: 0.5339 - val_loss: 1.2854 - val_accuracy: 0.5276\n",
      "Epoch 8/20\n",
      "244/244 [==============================] - 18s 76ms/step - loss: 1.2347 - accuracy: 0.5621 - val_loss: 1.3777 - val_accuracy: 0.5416\n",
      "Epoch 9/20\n",
      "244/244 [==============================] - 20s 82ms/step - loss: 1.1778 - accuracy: 0.5833 - val_loss: 1.2376 - val_accuracy: 0.5395\n",
      "Epoch 10/20\n",
      "244/244 [==============================] - 20s 83ms/step - loss: 1.1398 - accuracy: 0.6023 - val_loss: 1.2233 - val_accuracy: 0.5643\n",
      "Epoch 11/20\n",
      "244/244 [==============================] - 19s 79ms/step - loss: 1.1161 - accuracy: 0.6086 - val_loss: 1.1878 - val_accuracy: 0.5503\n",
      "Epoch 12/20\n",
      "244/244 [==============================] - 20s 80ms/step - loss: 1.0567 - accuracy: 0.6342 - val_loss: 1.0286 - val_accuracy: 0.6335\n",
      "Epoch 13/20\n",
      "244/244 [==============================] - 19s 80ms/step - loss: 1.0080 - accuracy: 0.6576 - val_loss: 1.1195 - val_accuracy: 0.5892\n",
      "Epoch 14/20\n",
      "244/244 [==============================] - 19s 79ms/step - loss: 0.9969 - accuracy: 0.6671 - val_loss: 1.0332 - val_accuracy: 0.6249\n",
      "Epoch 15/20\n",
      "244/244 [==============================] - 19s 79ms/step - loss: 0.9822 - accuracy: 0.6677 - val_loss: 1.0287 - val_accuracy: 0.6249\n",
      "Epoch 16/20\n",
      "244/244 [==============================] - 20s 80ms/step - loss: 0.9407 - accuracy: 0.6859 - val_loss: 1.0344 - val_accuracy: 0.5914\n",
      "Epoch 17/20\n",
      "244/244 [==============================] - 20s 80ms/step - loss: 0.9246 - accuracy: 0.6937 - val_loss: 1.0185 - val_accuracy: 0.6076\n",
      "Epoch 18/20\n",
      "244/244 [==============================] - 20s 80ms/step - loss: 0.8884 - accuracy: 0.7022 - val_loss: 1.0307 - val_accuracy: 0.6270\n",
      "Epoch 19/20\n",
      "244/244 [==============================] - 20s 80ms/step - loss: 0.8855 - accuracy: 0.7089 - val_loss: 1.0499 - val_accuracy: 0.6551\n",
      "Epoch 20/20\n",
      "244/244 [==============================] - 19s 79ms/step - loss: 0.8398 - accuracy: 0.7174 - val_loss: 1.0099 - val_accuracy: 0.6205\n",
      "Training completed in time:  0:06:29.415879 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "FOLD_K = 3\n",
    "\n",
    "print('-'*80)\n",
    "print(\"\\n({})\\n\".format(FOLD_K))\n",
    "    \n",
    "history = process_fold(FOLD_K, us8k_df, epochs=20)\n",
    "history1.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "behavioral-worker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "\n",
      "(4)\n",
      "\n",
      "Pre-training accuracy: 10.1010%\n",
      "\n",
      "Epoch 1/10\n",
      "242/242 [==============================] - 20s 82ms/step - loss: 2.2517 - accuracy: 0.1819 - val_loss: 2.1105 - val_accuracy: 0.2000\n",
      "Epoch 2/10\n",
      "242/242 [==============================] - 19s 80ms/step - loss: 1.8926 - accuracy: 0.2980 - val_loss: 1.8152 - val_accuracy: 0.3556\n",
      "Epoch 3/10\n",
      "242/242 [==============================] - 20s 83ms/step - loss: 1.6546 - accuracy: 0.3968 - val_loss: 1.7290 - val_accuracy: 0.3778\n",
      "Epoch 4/10\n",
      "242/242 [==============================] - 20s 84ms/step - loss: 1.5162 - accuracy: 0.4486 - val_loss: 1.4709 - val_accuracy: 0.4727\n",
      "Epoch 5/10\n",
      "242/242 [==============================] - 19s 79ms/step - loss: 1.4236 - accuracy: 0.4897 - val_loss: 1.3139 - val_accuracy: 0.5556\n",
      "Epoch 6/10\n",
      "242/242 [==============================] - 19s 79ms/step - loss: 1.3141 - accuracy: 0.5324 - val_loss: 1.2822 - val_accuracy: 0.5162\n",
      "Epoch 7/10\n",
      "242/242 [==============================] - 19s 77ms/step - loss: 1.2402 - accuracy: 0.5635 - val_loss: 1.2515 - val_accuracy: 0.5242\n",
      "Epoch 8/10\n",
      "242/242 [==============================] - 19s 77ms/step - loss: 1.1870 - accuracy: 0.5842 - val_loss: 1.1490 - val_accuracy: 0.6192\n",
      "Epoch 9/10\n",
      "242/242 [==============================] - 19s 78ms/step - loss: 1.1401 - accuracy: 0.6071 - val_loss: 1.1843 - val_accuracy: 0.5848\n",
      "Epoch 10/10\n",
      "242/242 [==============================] - 19s 79ms/step - loss: 1.0674 - accuracy: 0.6298 - val_loss: 1.1129 - val_accuracy: 0.6212\n",
      "Training completed in time:  0:03:13.796932 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "FOLD_K = 4\n",
    "\n",
    "print('-'*80)\n",
    "print(\"\\n({})\\n\".format(FOLD_K))\n",
    "    \n",
    "history = process_fold(FOLD_K, us8k_df, epochs=10)\n",
    "history1.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "binding-relation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "\n",
      "(5)\n",
      "\n",
      "Pre-training accuracy: 10.6838%\n",
      "\n",
      "Epoch 1/30\n",
      "244/244 [==============================] - 19s 78ms/step - loss: 2.2609 - accuracy: 0.1687 - val_loss: 1.9309 - val_accuracy: 0.2094\n",
      "Epoch 2/30\n",
      "244/244 [==============================] - 19s 76ms/step - loss: 1.9100 - accuracy: 0.2863 - val_loss: 1.7142 - val_accuracy: 0.3718\n",
      "Epoch 3/30\n",
      "244/244 [==============================] - 19s 77ms/step - loss: 1.6956 - accuracy: 0.3806 - val_loss: 1.4722 - val_accuracy: 0.4370\n",
      "Epoch 4/30\n",
      "244/244 [==============================] - 19s 78ms/step - loss: 1.5646 - accuracy: 0.4330 - val_loss: 1.5538 - val_accuracy: 0.4380\n",
      "Epoch 5/30\n",
      "244/244 [==============================] - 19s 78ms/step - loss: 1.4623 - accuracy: 0.4700 - val_loss: 1.2780 - val_accuracy: 0.5075\n",
      "Epoch 6/30\n",
      "244/244 [==============================] - 19s 78ms/step - loss: 1.3542 - accuracy: 0.5210 - val_loss: 1.2799 - val_accuracy: 0.5459\n",
      "Epoch 7/30\n",
      "244/244 [==============================] - 19s 77ms/step - loss: 1.2795 - accuracy: 0.5490 - val_loss: 1.1902 - val_accuracy: 0.5929\n",
      "Epoch 8/30\n",
      "244/244 [==============================] - 19s 77ms/step - loss: 1.2112 - accuracy: 0.5807 - val_loss: 1.2086 - val_accuracy: 0.5780\n",
      "Epoch 9/30\n",
      "244/244 [==============================] - 19s 77ms/step - loss: 1.1801 - accuracy: 0.5967 - val_loss: 1.1252 - val_accuracy: 0.5962\n",
      "Epoch 10/30\n",
      "244/244 [==============================] - 19s 78ms/step - loss: 1.1278 - accuracy: 0.6162 - val_loss: 1.0442 - val_accuracy: 0.6357\n",
      "Epoch 11/30\n",
      "244/244 [==============================] - 20s 81ms/step - loss: 1.0759 - accuracy: 0.6292 - val_loss: 1.0460 - val_accuracy: 0.6165\n",
      "Epoch 12/30\n",
      "244/244 [==============================] - 20s 81ms/step - loss: 1.0360 - accuracy: 0.6525 - val_loss: 0.9242 - val_accuracy: 0.6645\n",
      "Epoch 13/30\n",
      "244/244 [==============================] - 20s 81ms/step - loss: 0.9990 - accuracy: 0.6626 - val_loss: 1.0694 - val_accuracy: 0.5972\n",
      "Epoch 14/30\n",
      "244/244 [==============================] - 19s 80ms/step - loss: 0.9590 - accuracy: 0.6752 - val_loss: 1.1132 - val_accuracy: 0.6325\n",
      "Epoch 15/30\n",
      "244/244 [==============================] - 20s 80ms/step - loss: 0.9325 - accuracy: 0.6955 - val_loss: 0.9992 - val_accuracy: 0.5940\n",
      "Epoch 16/30\n",
      "244/244 [==============================] - 20s 80ms/step - loss: 0.8990 - accuracy: 0.7073 - val_loss: 1.0213 - val_accuracy: 0.6303\n",
      "Epoch 17/30\n",
      "244/244 [==============================] - 19s 79ms/step - loss: 0.8879 - accuracy: 0.7065 - val_loss: 0.8464 - val_accuracy: 0.6731\n",
      "Epoch 18/30\n",
      "244/244 [==============================] - 20s 80ms/step - loss: 0.8594 - accuracy: 0.7193 - val_loss: 0.8679 - val_accuracy: 0.6688\n",
      "Epoch 19/30\n",
      "244/244 [==============================] - 19s 79ms/step - loss: 0.8336 - accuracy: 0.7304 - val_loss: 0.9294 - val_accuracy: 0.6624\n",
      "Epoch 20/30\n",
      "244/244 [==============================] - 19s 80ms/step - loss: 0.8195 - accuracy: 0.7379 - val_loss: 0.9992 - val_accuracy: 0.6378\n",
      "Epoch 21/30\n",
      "244/244 [==============================] - 19s 80ms/step - loss: 0.7765 - accuracy: 0.7458 - val_loss: 0.9374 - val_accuracy: 0.6474\n",
      "Epoch 22/30\n",
      "244/244 [==============================] - 20s 80ms/step - loss: 0.7950 - accuracy: 0.7431 - val_loss: 0.8110 - val_accuracy: 0.7500\n",
      "Epoch 23/30\n",
      "244/244 [==============================] - 20s 81ms/step - loss: 0.7788 - accuracy: 0.7488 - val_loss: 0.7707 - val_accuracy: 0.7468\n",
      "Epoch 24/30\n",
      "244/244 [==============================] - 19s 79ms/step - loss: 0.7526 - accuracy: 0.7639 - val_loss: 0.8211 - val_accuracy: 0.7147\n",
      "Epoch 25/30\n",
      "244/244 [==============================] - 19s 80ms/step - loss: 0.7299 - accuracy: 0.7689 - val_loss: 0.8306 - val_accuracy: 0.6902\n",
      "Epoch 26/30\n",
      "244/244 [==============================] - 19s 79ms/step - loss: 0.7104 - accuracy: 0.7742 - val_loss: 0.9396 - val_accuracy: 0.6763\n",
      "Epoch 27/30\n",
      "244/244 [==============================] - 19s 79ms/step - loss: 0.7333 - accuracy: 0.7724 - val_loss: 0.8245 - val_accuracy: 0.7457\n",
      "Epoch 28/30\n",
      "244/244 [==============================] - 19s 80ms/step - loss: 0.7038 - accuracy: 0.7781 - val_loss: 0.8083 - val_accuracy: 0.7361\n",
      "Epoch 29/30\n",
      "244/244 [==============================] - 19s 79ms/step - loss: 0.6699 - accuracy: 0.7889 - val_loss: 0.8271 - val_accuracy: 0.7564\n",
      "Epoch 30/30\n",
      "244/244 [==============================] - 19s 79ms/step - loss: 0.7001 - accuracy: 0.7790 - val_loss: 0.8706 - val_accuracy: 0.7147\n",
      "Training completed in time:  0:09:38.833439 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "FOLD_K = 5\n",
    "\n",
    "print('-'*80)\n",
    "print(\"\\n({})\\n\".format(FOLD_K))\n",
    "    \n",
    "history = process_fold(FOLD_K, us8k_df, epochs=30)\n",
    "history1.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "front-apparel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "\n",
      "(6)\n",
      "\n",
      "Pre-training accuracy: 5.5893%\n",
      "\n",
      "Epoch 1/30\n",
      "248/248 [==============================] - 20s 78ms/step - loss: 2.2365 - accuracy: 0.1588 - val_loss: 1.9805 - val_accuracy: 0.2807\n",
      "Epoch 2/30\n",
      "248/248 [==============================] - 20s 80ms/step - loss: 1.8864 - accuracy: 0.2980 - val_loss: 1.7456 - val_accuracy: 0.3791\n",
      "Epoch 3/30\n",
      "248/248 [==============================] - 20s 79ms/step - loss: 1.6592 - accuracy: 0.3826 - val_loss: 1.5047 - val_accuracy: 0.4532\n",
      "Epoch 4/30\n",
      "248/248 [==============================] - 19s 76ms/step - loss: 1.4833 - accuracy: 0.4685 - val_loss: 1.3374 - val_accuracy: 0.4763\n",
      "Epoch 5/30\n",
      "248/248 [==============================] - 19s 75ms/step - loss: 1.3562 - accuracy: 0.5076 - val_loss: 1.3489 - val_accuracy: 0.4982\n",
      "Epoch 6/30\n",
      "248/248 [==============================] - 19s 76ms/step - loss: 1.2467 - accuracy: 0.5471 - val_loss: 1.2643 - val_accuracy: 0.5407\n",
      "Epoch 7/30\n",
      "248/248 [==============================] - 20s 81ms/step - loss: 1.1822 - accuracy: 0.5726 - val_loss: 1.2174 - val_accuracy: 0.5577\n",
      "Epoch 8/30\n",
      "248/248 [==============================] - 20s 80ms/step - loss: 1.1505 - accuracy: 0.5908 - val_loss: 1.2801 - val_accuracy: 0.5504\n",
      "Epoch 9/30\n",
      "248/248 [==============================] - 19s 75ms/step - loss: 1.0961 - accuracy: 0.6170 - val_loss: 1.1794 - val_accuracy: 0.5966\n",
      "Epoch 10/30\n",
      "248/248 [==============================] - 19s 76ms/step - loss: 1.0445 - accuracy: 0.6395 - val_loss: 1.1678 - val_accuracy: 0.6100\n",
      "Epoch 11/30\n",
      "248/248 [==============================] - 19s 75ms/step - loss: 1.0221 - accuracy: 0.6461 - val_loss: 1.0848 - val_accuracy: 0.6476\n",
      "Epoch 12/30\n",
      "248/248 [==============================] - 19s 76ms/step - loss: 0.9530 - accuracy: 0.6768 - val_loss: 1.1286 - val_accuracy: 0.6209\n",
      "Epoch 13/30\n",
      "248/248 [==============================] - 19s 76ms/step - loss: 0.9295 - accuracy: 0.6828 - val_loss: 1.1408 - val_accuracy: 0.6343\n",
      "Epoch 14/30\n",
      "248/248 [==============================] - 19s 76ms/step - loss: 0.9227 - accuracy: 0.6901 - val_loss: 1.1231 - val_accuracy: 0.6258\n",
      "Epoch 15/30\n",
      "248/248 [==============================] - 19s 76ms/step - loss: 0.8906 - accuracy: 0.7038 - val_loss: 1.2340 - val_accuracy: 0.6221\n",
      "Epoch 16/30\n",
      "248/248 [==============================] - 19s 77ms/step - loss: 0.8680 - accuracy: 0.7127 - val_loss: 1.1147 - val_accuracy: 0.6245\n",
      "Epoch 17/30\n",
      "248/248 [==============================] - 20s 81ms/step - loss: 0.8863 - accuracy: 0.7039 - val_loss: 1.0663 - val_accuracy: 0.6367\n",
      "Epoch 18/30\n",
      "248/248 [==============================] - 20s 81ms/step - loss: 0.8318 - accuracy: 0.7313 - val_loss: 1.2748 - val_accuracy: 0.6488\n",
      "Epoch 19/30\n",
      "248/248 [==============================] - 20s 79ms/step - loss: 0.8274 - accuracy: 0.7317 - val_loss: 1.2079 - val_accuracy: 0.6258\n",
      "Epoch 20/30\n",
      "248/248 [==============================] - 20s 79ms/step - loss: 0.7962 - accuracy: 0.7407 - val_loss: 1.2993 - val_accuracy: 0.5990\n",
      "Epoch 21/30\n",
      "248/248 [==============================] - 20s 79ms/step - loss: 0.7716 - accuracy: 0.7479 - val_loss: 1.2160 - val_accuracy: 0.6574\n",
      "Epoch 22/30\n",
      "248/248 [==============================] - 20s 80ms/step - loss: 0.7675 - accuracy: 0.7567 - val_loss: 1.0856 - val_accuracy: 0.6719\n",
      "Epoch 23/30\n",
      "248/248 [==============================] - 20s 79ms/step - loss: 0.7788 - accuracy: 0.7583 - val_loss: 1.2997 - val_accuracy: 0.6476\n",
      "Epoch 24/30\n",
      "248/248 [==============================] - 20s 79ms/step - loss: 0.7356 - accuracy: 0.7660 - val_loss: 1.2796 - val_accuracy: 0.6148\n",
      "Epoch 25/30\n",
      "248/248 [==============================] - 20s 79ms/step - loss: 0.7005 - accuracy: 0.7786 - val_loss: 1.1350 - val_accuracy: 0.6501\n",
      "Epoch 26/30\n",
      "248/248 [==============================] - 20s 79ms/step - loss: 0.7150 - accuracy: 0.7763 - val_loss: 1.2734 - val_accuracy: 0.6707\n",
      "Epoch 27/30\n",
      "248/248 [==============================] - 20s 79ms/step - loss: 0.7012 - accuracy: 0.7814 - val_loss: 1.3249 - val_accuracy: 0.6306\n",
      "Epoch 28/30\n",
      "248/248 [==============================] - 20s 80ms/step - loss: 0.6892 - accuracy: 0.7840 - val_loss: 1.0920 - val_accuracy: 0.6695\n",
      "Epoch 29/30\n",
      "248/248 [==============================] - 20s 79ms/step - loss: 0.7034 - accuracy: 0.7776 - val_loss: 1.2737 - val_accuracy: 0.6537\n",
      "Epoch 30/30\n",
      "248/248 [==============================] - 20s 79ms/step - loss: 0.6599 - accuracy: 0.7961 - val_loss: 1.1370 - val_accuracy: 0.6634\n",
      "Training completed in time:  0:09:42.139028 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "FOLD_K = 6\n",
    "\n",
    "print('-'*80)\n",
    "print(\"\\n({})\\n\".format(FOLD_K))\n",
    "    \n",
    "history = process_fold(FOLD_K, us8k_df, epochs=30)\n",
    "history1.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "elder-saint",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "\n",
      "(7)\n",
      "\n",
      "Pre-training accuracy: 11.9332%\n",
      "\n",
      "Epoch 1/30\n",
      "247/247 [==============================] - 21s 82ms/step - loss: 2.3707 - accuracy: 0.1173 - val_loss: 2.2856 - val_accuracy: 0.1348\n",
      "Epoch 2/30\n",
      "247/247 [==============================] - 20s 80ms/step - loss: 2.2794 - accuracy: 0.1239 - val_loss: 2.2724 - val_accuracy: 0.1301\n",
      "Epoch 3/30\n",
      "247/247 [==============================] - 19s 76ms/step - loss: 2.2550 - accuracy: 0.1292 - val_loss: 2.1864 - val_accuracy: 0.1969\n",
      "Epoch 4/30\n",
      "247/247 [==============================] - 19s 76ms/step - loss: 2.1683 - accuracy: 0.1704 - val_loss: 2.0446 - val_accuracy: 0.2458\n",
      "Epoch 5/30\n",
      "247/247 [==============================] - 20s 79ms/step - loss: 2.0626 - accuracy: 0.2238 - val_loss: 1.9775 - val_accuracy: 0.2482\n",
      "Epoch 6/30\n",
      "247/247 [==============================] - 19s 79ms/step - loss: 1.9658 - accuracy: 0.2624 - val_loss: 1.8734 - val_accuracy: 0.2673\n",
      "Epoch 7/30\n",
      "247/247 [==============================] - 20s 80ms/step - loss: 1.8261 - accuracy: 0.3271 - val_loss: 1.7061 - val_accuracy: 0.3377\n",
      "Epoch 8/30\n",
      "247/247 [==============================] - 20s 79ms/step - loss: 1.6420 - accuracy: 0.4028 - val_loss: 1.5929 - val_accuracy: 0.3544\n",
      "Epoch 9/30\n",
      "247/247 [==============================] - 19s 79ms/step - loss: 1.5320 - accuracy: 0.4467 - val_loss: 1.5277 - val_accuracy: 0.4057\n",
      "Epoch 10/30\n",
      "247/247 [==============================] - 20s 79ms/step - loss: 1.4297 - accuracy: 0.4883 - val_loss: 1.4771 - val_accuracy: 0.4033\n",
      "Epoch 11/30\n",
      "247/247 [==============================] - 19s 78ms/step - loss: 1.3777 - accuracy: 0.5032 - val_loss: 1.3826 - val_accuracy: 0.4284\n",
      "Epoch 12/30\n",
      "247/247 [==============================] - 20s 82ms/step - loss: 1.3374 - accuracy: 0.5318 - val_loss: 1.3652 - val_accuracy: 0.4570\n",
      "Epoch 13/30\n",
      "247/247 [==============================] - 20s 80ms/step - loss: 1.2774 - accuracy: 0.5443 - val_loss: 1.4501 - val_accuracy: 0.4940\n",
      "Epoch 14/30\n",
      "247/247 [==============================] - 20s 79ms/step - loss: 1.2263 - accuracy: 0.5689 - val_loss: 1.2995 - val_accuracy: 0.4857\n",
      "Epoch 15/30\n",
      "247/247 [==============================] - 20s 81ms/step - loss: 1.1720 - accuracy: 0.5892 - val_loss: 1.2647 - val_accuracy: 0.5477\n",
      "Epoch 16/30\n",
      "247/247 [==============================] - 20s 80ms/step - loss: 1.1421 - accuracy: 0.5939 - val_loss: 1.2690 - val_accuracy: 0.5286\n",
      "Epoch 17/30\n",
      "247/247 [==============================] - 30s 123ms/step - loss: 1.1098 - accuracy: 0.6148 - val_loss: 1.2350 - val_accuracy: 0.5573\n",
      "Epoch 18/30\n",
      "247/247 [==============================] - 31s 125ms/step - loss: 1.0599 - accuracy: 0.6329 - val_loss: 1.2729 - val_accuracy: 0.5251\n",
      "Epoch 19/30\n",
      "247/247 [==============================] - 30s 123ms/step - loss: 1.0467 - accuracy: 0.6372 - val_loss: 1.2105 - val_accuracy: 0.5465\n",
      "Epoch 20/30\n",
      "247/247 [==============================] - 30s 122ms/step - loss: 1.0402 - accuracy: 0.6421 - val_loss: 1.2334 - val_accuracy: 0.5334\n",
      "Epoch 21/30\n",
      "247/247 [==============================] - 30s 122ms/step - loss: 0.9570 - accuracy: 0.6735 - val_loss: 1.1120 - val_accuracy: 0.5943\n",
      "Epoch 22/30\n",
      "247/247 [==============================] - 30s 122ms/step - loss: 0.9631 - accuracy: 0.6719 - val_loss: 1.0969 - val_accuracy: 0.5847\n",
      "Epoch 23/30\n",
      "247/247 [==============================] - 31s 125ms/step - loss: 0.9235 - accuracy: 0.6907 - val_loss: 1.1379 - val_accuracy: 0.6038\n",
      "Epoch 24/30\n",
      "247/247 [==============================] - 21s 83ms/step - loss: 0.9117 - accuracy: 0.6979 - val_loss: 1.1342 - val_accuracy: 0.6026\n",
      "Epoch 25/30\n",
      "247/247 [==============================] - 19s 77ms/step - loss: 0.9094 - accuracy: 0.6990 - val_loss: 1.2830 - val_accuracy: 0.5489\n",
      "Epoch 26/30\n",
      "247/247 [==============================] - 20s 80ms/step - loss: 0.8900 - accuracy: 0.7023 - val_loss: 1.0895 - val_accuracy: 0.5859\n",
      "Epoch 27/30\n",
      "247/247 [==============================] - 19s 78ms/step - loss: 0.8968 - accuracy: 0.6989 - val_loss: 1.0863 - val_accuracy: 0.5859\n",
      "Epoch 28/30\n",
      "247/247 [==============================] - 19s 79ms/step - loss: 0.8519 - accuracy: 0.7242 - val_loss: 1.0588 - val_accuracy: 0.6086\n",
      "Epoch 29/30\n",
      "247/247 [==============================] - 18s 75ms/step - loss: 0.8323 - accuracy: 0.7278 - val_loss: 1.1321 - val_accuracy: 0.5883\n",
      "Epoch 30/30\n",
      "247/247 [==============================] - 19s 76ms/step - loss: 0.8134 - accuracy: 0.7345 - val_loss: 1.0783 - val_accuracy: 0.6146\n",
      "Training completed in time:  0:11:02.430352 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "FOLD_K = 7\n",
    "\n",
    "print('-'*80)\n",
    "print(\"\\n({})\\n\".format(FOLD_K))\n",
    "    \n",
    "history = process_fold(FOLD_K, us8k_df, epochs=30)\n",
    "history1.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "major-subject",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD_K = 8\n",
    "\n",
    "print('-'*80)\n",
    "print(\"\\n({})\\n\".format(FOLD_K))\n",
    "    \n",
    "history = process_fold(FOLD_K, us8k_df, epochs=10)\n",
    "history1.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-wallace",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD_K = 9\n",
    "\n",
    "print('-'*80)\n",
    "print(\"\\n({})\\n\".format(FOLD_K))\n",
    "    \n",
    "history = process_fold(FOLD_K, us8k_df, epochs=10)\n",
    "history1.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-neighborhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD_K = 10\n",
    "\n",
    "print('-'*80)\n",
    "print(\"\\n({})\\n\".format(FOLD_K))\n",
    "    \n",
    "history = process_fold(FOLD_K, us8k_df, epochs=10)\n",
    "history1.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electric-colorado",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
